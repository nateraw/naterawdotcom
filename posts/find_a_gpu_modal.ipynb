{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Text Yourself When GPUs Are Available\"\n",
    "description: \"Quick guide on setting up an app on Modal that'll text you when instances become available on Lambda Labs Cloud.\"\n",
    "author: \"Nate Raw\"\n",
    "date: \"2023-07-24\"\n",
    "categories: [code, guide, modal, automation]\n",
    "image: ../static/find_a_gpu_modal/thumbnail.jpg\n",
    "notebook-view:\n",
    "  - notebook: find_a_gpu_modal.ipynb\n",
    "    title: \"Find a gpu on modal\"\n",
    "    url: https://colab.research.google.com/github/nateraw/replicate-examples/notebook/find_a_gpu_modal.ipynb\n",
    "notebook-links: inline\n",
    "format: \n",
    "  html: default\n",
    "  ipynb: default\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs - so hot right now! It's getting to the point where all available GPU instances are unavailable, which is a bummer if you're trying to train a model.\n",
    "\n",
    "As of writing this, Lambda Cloud is my favorite cloud GPU provider. They have great instances, an easy to use UI, and the best prices. The only downside is that they're often sold out. So, let's see what we can do about that.\n",
    "\n",
    "## The Plan\n",
    "\n",
    "To make things easier, I put together a small Python library called [lambdacloud](https://github.com/nateraw/lambdacloud) that makes it easy to interface with the Lambda Cloud API. We'll use this to check for available instances and spin them up.\n",
    "\n",
    "We'll also use [Twilio](https://twilio.com) to send text messages. You'll need a Twilio account and a phone number that can send SMS messages.\n",
    "\n",
    "To avoid having to run this script all the time from your local machine, we'll use [Modal](https://modal.com) to run the script on a schedule. Modal is a cloud orchestration platform that makes it easy to run code on cloud machines. Using it for this use case shouldn't cost more than a few cents, but you can just follow along with the code and run it locally if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lambdacloud twilio modal-client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to authenticate with Modal if you haven't already..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! modal token new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To authenticate with Lambda's API, you'll need an API key, which you can generate [here](https://cloud.lambdalabs.com/api-keys) when you're logged in.\n",
    "\n",
    "Additionally, you'll need Twilio's account identifier, auth token, and phone number, which you can find [here](https://www.twilio.com/console). The phone number will be the one you'll receive texts from, and it should be fairly easy to figure out how to set that up if you haven't already.\n",
    "\n",
    "Now that we have all our credentials, we'll log into Modal and create a collection of secrets. See the docs on this feature [here](https://modal.com/docs/guide/secrets).\n",
    "\n",
    "I've named my collection \"twilio\" and added the following environment variables:\n",
    "  - `TWILIO_SID`: Twilio account identifier\n",
    "  - `TWILIO_AUTH`: Your Twilio auth token\n",
    "  - `TWILIO_PHONE`: Your Twilio phone number (Make sure to include the country code, e.g. +1 for US)\n",
    "  - `TO_PHONE`: Your phone number you want to receive texts on (Make sure to include the country code, e.g. +1 for US)\n",
    "  - `LAMBDA_SECRET`: Your Lambda Labs Cloud API Key\n",
    "\n",
    "![Modal Secrets](../static/find_a_gpu_modal/modal_secrets.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code\n",
    "\n",
    "Everything's ready, we just have to write a small script now ðŸš€. Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import modal\n",
    "\n",
    "\n",
    "stub = modal.Stub()\n",
    "\n",
    "# Defines our environment, installs necessary packages\n",
    "my_image = modal.Image.debian_slim().pip_install(\"lambdacloud\", \"twilio\")\n",
    "\n",
    "# Replace these with your own values\n",
    "DESIRED_INSTANCE_TYPES = [\"gpu_8x_a100_80gb_sxm4\", \"gpu_8x_a100\", \"gpu_8x_v100\"]\n",
    "\n",
    "\n",
    "@stub.function(image=my_image, schedule=modal.Cron(\"*/5 3-9 * * 1-5\"), secret=modal.Secret.from_name(\"twilio\"))\n",
    "def poll_lambda_for_big_instances():\n",
    "    from lambdacloud import list_instance_types, login\n",
    "    from twilio.rest import Client\n",
    "\n",
    "    # Auth with lambda\n",
    "    login(token=os.environ[\"LAMBDA_SECRET\"])\n",
    "\n",
    "    # Auth with twilio\n",
    "    account_sid = os.environ[\"TWILIO_SID\"]\n",
    "    auth_token = os.environ[\"TWILIO_AUTH\"]\n",
    "    client = Client(account_sid, auth_token)\n",
    "\n",
    "    from_phone = os.environ[\"TWILIO_PHONE\"]\n",
    "    to_phone = os.environ[\"TO_PHONE\"]\n",
    "\n",
    "    instances_available = [x.name for x in list_instance_types()]\n",
    "    nl = \"\\n\"\n",
    "    print(f\"Instances available:{nl}âœ… - {f'{nl}âœ… - '.join(instances_available)}\")\n",
    "\n",
    "    desired_instances_available = []\n",
    "    for desired_instance in DESIRED_INSTANCE_TYPES:\n",
    "        if desired_instance in instances_available:\n",
    "            desired_instances_available.append(desired_instance)\n",
    "\n",
    "    if len(desired_instances_available):\n",
    "        body = f\"The following instances are available on Lambda Cloud: {', '.join(desired_instances_available)}.\"\n",
    "        message = client.messages.create(from_=from_phone, to=to_phone, body=body)\n",
    "        print(f\"Message sent - SID: {message.sid}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    modal.runner.deploy_stub(stub, name=\"lambda-watcher\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, you should get a text message when an instance becomes available. You can also check the logs in Modal to see what's going on. In the UI, you should see something like this for the deployment:\n",
    "\n",
    "![Modal Logs](../static/find_a_gpu_modal/modal_logs.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now you can text yourself when GPUs are available. It's fairly easy to extend this script to spin up instances that are available, just use the `lambdacloud.create_instance` function. I'll leave that to you as homework ðŸ˜Ž."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuego-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
