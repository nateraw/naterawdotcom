{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Multi-Node Training with Hugging Face accelerate and AzureML\"\n",
        "description: \"In this guide, we'll see how you can do multi-node/multi-GPU training on AzureML using Hugging Face `accelerate`.\"\n",
        "author: \"Nate Raw\"\n",
        "date: \"2022-11-30\"\n",
        "categories: [code, guide, azure, huggingface]\n",
        "image: ../static/multinode_training_accelerate_azureml/thumbnail.jpg\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zzJvvjF1Q3Qr"
      },
      "source": [
        "In this guide, we'll see how you can do multi-node/multi-GPU training on AzureML using Hugging Face `accelerate`.\n",
        "\n",
        "More specifically, we'll fine-tune an image classification model from `timm` on the CIFAR10 dataset. We use this dataset as it is small and works well for getting started.\n",
        "\n",
        "Prerequisites:\n",
        "\n",
        "  - You have already [created an AzureML workspace](https://learn.microsoft.com/en-us/azure/machine-learning/quickstart-create-resources)\n",
        "  - You have your workspace's associated subscription ID, Resource Group name, and AzureML workspace name.\n",
        "  - You have the necessary quota for GPU instances, so you can follow along."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a2GTwNxARigO"
      },
      "source": [
        "# Step 0 - Setup Local Environment\n",
        "\n",
        "First things first, we'll need to set up a local environment that has the required dependencies to interface with AzureML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtqX8L_WRwsm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install azure-core azure-ai-ml\n",
        "! curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l584eN0wSCN5"
      },
      "source": [
        "Next, we login with the Azure CLI. If you're running on your own machine and not a notebook, you can run this in your terminal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfP00KuXSRL4"
      },
      "outputs": [],
      "source": [
        "! az login"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gqKv8m9LVm7q"
      },
      "source": [
        "Here we define all the imports needed for this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9pEv0DaVmdi"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml import Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.entities import Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DktPSG9IUZcg"
      },
      "outputs": [],
      "source": [
        "# Authenticate!\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Run this to check auth worked\n",
        "credential.get_token(\"https://management.azure.com/.default\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AAhKPlfTUTXr"
      },
      "source": [
        "Now, we should be able to authenticate with AzureML SDKv2 to connect to our workspace.\n",
        "\n",
        "**For that, we'll need some info from you, which you'll have to replace in the cell below.**\n",
        "\n",
        "  - Subscription ID: The Azure subscription where your resource was created.\n",
        "  - Resource Group Name: The name of the Azure Resource Group your AzureML Resource was created.\n",
        "  - Workspace Name: The name of your AzureML Resource\n",
        "\n",
        "All of this information can be found in the Azure Portal. Just navigate to the AzureML Resource and find it in the \"Overview\" seciton. ‚úÖ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-3fbJHoUoxx"
      },
      "outputs": [],
      "source": [
        "# Replace these values with yours!\n",
        "aml_sub=\"YOUR AZUREML SUBSCRIPTION ID\"\n",
        "aml_rsg=\"NAME OF AZURE RESOURCE GROUP YOUR INSTANCE WAS CREATED IN\"\n",
        "aml_ws_name = \"NAME OF YOUR AZUREML RESOURCE\"\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=aml_sub,\n",
        "    resource_group_name=aml_rsg,\n",
        "    workspace_name=aml_ws_name,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4AW6q69ETGnV"
      },
      "source": [
        "# Step 2 - Create Compute Targets\n",
        "\n",
        "Next, you'll want to make a couple compute targets. There are many ways to do this, but for this example, we will just use the Web UI. \n",
        "\n",
        "Navigate to your [AzureML Portal](https://ml.azure.com), and create two compute clusters:\n",
        "\n",
        "  - One named `cpu-cluster` which is a CPU instance. You can set min nodes to 0 and max nodes to 1.\n",
        "    - Set min nodes to 0\n",
        "    - Set max nodes to 1\n",
        "\n",
        "  - Another named `gpu-cluster` which is a GPU cluster. For this example, we used `Standard_NC12` instances.\n",
        "    - Set min nodes to 0\n",
        "    - Set max nodes to 2\n",
        "\n",
        "<Tip>\n",
        "As mentioned in the prerequisites at the start of the notebook, you will need to request a quota increase to make sure you have access to enough compute to follow along. Azure usually responds within 12-24 hours, in my experience.\n",
        "</Tip>\n",
        "\n",
        "For more detailed instructions on creating compute clusters, you can refer to the [AzureML Docs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-manage-compute-instance?tabs=azure-studio)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFjLhyfnU5ga"
      },
      "outputs": [],
      "source": [
        "# If your targets aren't named as described above, feel free to update here.\n",
        "cpu_compute_target = 'cpu-cluster'\n",
        "gpu_compute_target = 'gpu-cluster'\n",
        "\n",
        "# Train on 2 nodes with 2 GPUs each (4 GPUs total).\n",
        "# If you didn 't use Standard_NC12 instances, or if you desire a different number of nodes\n",
        "# per training run, you may need to update these values accordingly.\n",
        "num_training_nodes = 2\n",
        "num_gpus_per_node = 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p6BfYoM7TKcK"
      },
      "source": [
        "# Step 3 - Upload Data to AzureML\n",
        "\n",
        "Can't do much training if we don't have any data! üòÖ\n",
        "\n",
        "So, let's get some data into AzureML! To do that, we'll create a `data-prep-step` that:\n",
        "\n",
        "  - downloads compressed data from a URL,\n",
        "  - extracts it to a new location in AzureML workspace's storage\n",
        "\n",
        "Once we do this, we'll be able to mount this data to our training run later. üíæ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GNvO0_W1eek2"
      },
      "source": [
        "We start off by creating a `./src` directory where all of our code will live. AzureML uploads all the files within this source directory, so we want to keep it clean.\n",
        "\n",
        "We'll also define an experiment name, so all the jobs we run here are grouped together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euk2vdfPVKnT"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "experiment_name = 'accelerate-cv-multinode-example'\n",
        "src_dir = './src'\n",
        "Path(src_dir).mkdir(exist_ok=True, parents=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x_RuPfO8YM6C"
      },
      "source": [
        "## Define Data Upload Script\n",
        "\n",
        "Here's the data upload script. It simply takes in a path (to a `.tar.gz` file) and extracts it to `output_folder`. üìù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4VrJGGaTasr"
      },
      "outputs": [],
      "source": [
        "%%writefile {src_dir}/read_write_data.py\n",
        "import argparse\n",
        "import os\n",
        "import tarfile\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input_data\", type=str)\n",
        "parser.add_argument(\"--output_folder\", type=str)\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "file = tarfile.open(args.input_data)\n",
        "output_path = os.path.join(args.output_folder)\n",
        "file.extractall(output_path)\n",
        "file.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6z2Z4MegTOsK"
      },
      "source": [
        "## Define Data Upload Job\n",
        "\n",
        "Now that we have some code to run, we can define the job. The below basically defines:\n",
        "\n",
        "  - **Inputs:** The inputs to our script. In our case it's a `tar.gz` file stored at a URL. This will be downloaded when the job runs. We provide it to our script we wrote above via the `--input_data` flag.\n",
        "  - **Outputs:** The path where we will save the outputs in our workspace's data store. We pass this to `--output_folder` in our script.\n",
        "  - **Environment:** We use one of AzureML's curated environments, which will result in the job starting faster. Later, for the training job, we'll define a custom environment.\n",
        "  - **Compute:** We tell the job to run on our `cpu-cluster`.\n",
        "\n",
        "Any inputs/outputs you define can be referenced via `${{inputs.<name>}}` and `${{outputs.<name>}}` in the `command`, so the values are passed along to the script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g4ZmvJ9VgCV"
      },
      "outputs": [],
      "source": [
        "# Input in this case is a URL that will be downloaded\n",
        "inputs = {\n",
        "    \"pets_zip\": Input(\n",
        "        type=AssetTypes.URI_FILE,\n",
        "        path=\"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\",\n",
        "    ),\n",
        "}\n",
        "\n",
        "# Define output data. The resulting path will be used in run.py\n",
        "outputs = {\n",
        "    \"pets\": Output(\n",
        "        type=AssetTypes.URI_FOLDER,\n",
        "        path=f\"azureml://subscriptions/{aml_sub}/resourcegroups/{aml_rsg}/workspaces/{aml_ws_name}/datastores/workspaceblobstore/paths/PETS\",\n",
        "    )\n",
        "}\n",
        "\n",
        "# Define our job\n",
        "job = command(\n",
        "    code=src_dir,\n",
        "    command=\"python read_write_data.py --input_data ${{inputs.pets_zip}} --output_folder ${{outputs.pets}}\",\n",
        "    inputs=inputs,\n",
        "    outputs=outputs,\n",
        "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
        "    compute=cpu_compute_target,\n",
        "    experiment_name=experiment_name,\n",
        "    display_name='data-prep-step'\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fqTw176aTbBL"
      },
      "source": [
        "## Run Data Upload Job\n",
        "\n",
        "If everything goes smoothly, the below should launch the `data-prep` job, and spit out a link for you to watch it run.\n",
        "\n",
        "You only really need to run this job once, and then can reference it as many times as you like in the training step we are going to define in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehNUa8xUTcyB"
      },
      "outputs": [],
      "source": [
        "# submit the command\n",
        "returned_job = ml_client.jobs.create_or_update(job)\n",
        "returned_job"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bHTm_rfMTO7t"
      },
      "source": [
        "# Step 4 - Train\n",
        "\n",
        "Ok, we have some data! üôè\n",
        "\n",
        "Let's see how we can set up multi-node/multi-gpu training with `accelerate`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YdPe8KnTTSta"
      },
      "source": [
        "## Define Training Environment\n",
        "\n",
        "For the training job, we'll define a custom training environment, as our dependencies aren't included in the curated environments offered by AzureML. We try to pin most of these to very specific versions so the environment won't break in the future/if we share it with others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRZjeIwFTUxK"
      },
      "outputs": [],
      "source": [
        "%%writefile {src_dir}/train_environment.yml\n",
        "name: aml-video-accelerate\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.9\n",
        "  - numpy\n",
        "  - pip\n",
        "  - scikit-learn\n",
        "  - scipy\n",
        "  - pandas\n",
        "  - pip:\n",
        "    - pyarrow==9.0.0\n",
        "    - azure-identity>=1.8.0\n",
        "    - transformers==4.24.0\n",
        "    - timm==0.6.12\n",
        "    - git+https://github.com/huggingface/accelerate.git@5315290b55ea9babd95a281a27c51d87b89d7c85\n",
        "    - fire==0.4.0\n",
        "    - torchmetrics==0.10.3\n",
        "    - av==9.2.0\n",
        "    - torch==1.12.1\n",
        "    - torchvision==0.13.1\n",
        "    - tensorboard\n",
        "    - mlflow \n",
        "    - setfit\n",
        "    - azure-keyvault-secrets\n",
        "    - azureml-mlflow\n",
        "    - azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fGChn-S7gyk-"
      },
      "source": [
        "Now we use the conda environment file we just wrote to specify additional dependencies on top of the curated `openmpi3.1.2-ubuntu18.04` docker image from AzureML.\n",
        "\n",
        "For more information on creating environments in AzureML SDK v2, check out the [docs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-environments-v2?tabs=python)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VnlHXhpWTQy"
      },
      "outputs": [],
      "source": [
        "# Define environment from conda specification\n",
        "train_environment = Environment(\n",
        "    name=\"aml-accelerate\",\n",
        "    description=\"Custom environment for Accelerate + PytorchVideo training\",\n",
        "    conda_file=str(Path(src_dir) / \"train_environment.yml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lJeVxEFJXn7G"
      },
      "source": [
        "## Define Training Script\n",
        "\n",
        "For our training script, we're going to use the [`complete_cv_example.py`](https://github.com/huggingface/accelerate/blob/main/examples/complete_cv_example.py) script from the official [`accelerate` examples](https://github.com/huggingface/accelerate/tree/main/examples) on GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRyE6f5fY2Bj"
      },
      "outputs": [],
      "source": [
        "! wget -O {src_dir}/train.py -nc https://raw.githubusercontent.com/huggingface/accelerate/main/examples/complete_cv_example.py"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rto1Z01xTVE7"
      },
      "source": [
        "## Define Training Job\n",
        "\n",
        "The moment of truth! Let's see if we can train an image classifier using multiple GPUs across multiple nodes on AzureML ü§û\n",
        "\n",
        "Here, we'll define a job called `train-step` where we define:\n",
        "\n",
        "  - An input, `pets`, which points to the data store path where we stored our processed data earlier.\n",
        "  - Our training command, providing the following flags:\n",
        "    - `--data_dir`: supplying the input reference path\n",
        "    - `--with_tracking`: To make sure we save logs\n",
        "    - `--checkpointing_steps epoch`: To make sure we are saving checkpoints every epoch\n",
        "    - `--output_dir ./outputs`: Save to the `./outputs` directory, which is a special directory in AzureML meant for saving any artifacts from training.\n",
        "  - Our `training_environment` we defined above.\n",
        "  - The `distribution` as `PyTorch`, specifying `process_count_per_instance`, which is how many GPUs there are per node. (in our case, 2).\n",
        "\n",
        "For more information on how Multi-Node GPU training works on AzureML, you can refer to the [docs](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-distributed-gpu)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_F0xvskTWUQ"
      },
      "outputs": [],
      "source": [
        "# Define inputs, which in our case is the path from upload_cats_and_dogs.py\n",
        "inputs = dict(\n",
        "    pets=Input(\n",
        "        type=AssetTypes.URI_FOLDER,\n",
        "        path=f\"azureml://subscriptions/{aml_sub}/resourcegroups/{aml_rsg}/workspaces/{aml_ws_name}/datastores/workspaceblobstore/paths/PETS/images\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Define the job!\n",
        "job = command(\n",
        "    code=src_dir,\n",
        "    inputs=inputs,\n",
        "    command=\"python train.py --data_dir ${{inputs.pets}} --with_tracking --checkpointing_steps epoch --output_dir ./outputs\",\n",
        "    environment=train_environment,\n",
        "    compute=gpu_compute_target,\n",
        "    instance_count=num_training_nodes,  # In this, only 2 node cluster was created.\n",
        "    distribution={\n",
        "        \"type\": \"PyTorch\",\n",
        "        # set process count to the number of gpus per node\n",
        "        # In our case (using Standard_NC12) we have 2 GPUs per node.\n",
        "        \"process_count_per_instance\": num_gpus_per_node,\n",
        "    },\n",
        "    experiment_name=experiment_name,\n",
        "    display_name='train-step'\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kkADwqp3TXLJ"
      },
      "source": [
        "## Run Training Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYg7RNzgTYMT"
      },
      "outputs": [],
      "source": [
        "# Run it! üöÄ\n",
        "train_job = ml_client.jobs.create_or_update(job)\n",
        "train_job"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNDjnYJwnLpFcevvLdgN0Kx",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
