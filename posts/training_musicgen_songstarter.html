<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nate Raw">
<meta name="dcterms.date" content="2024-04-24">
<meta name="description" content="Explaining the motivation and process behind training MusicGen Songstarter, a model that generates useful song ideas for music producers.">

<title>nateraw.com - Why and How I trained MusicGen Songstarter</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-QQ37HV1W85"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QQ37HV1W85', { 'anonymize_ip': true});
</script>


<meta name="twitter:title" content="nateraw.com - Why and How I trained MusicGen Songstarter">
<meta name="twitter:description" content="Explaining the motivation and process behind training MusicGen Songstarter, a model that generates useful song ideas for music producers.">
<meta name="twitter:image" content="https://www.nateraw.com/static/training_musicgen_songstarter/thumbnail.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">nateraw.com</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/nateraw/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/_nateraw"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/Nathan-Raw/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page">
      <h1 class="title">Why and How I trained MusicGen Songstarter</h1>
                  <div>
        <div class="description">
          Explaining the motivation and process behind training MusicGen Songstarter, a model that generates useful song ideas for music producers.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">audio</div>
                <div class="quarto-category">training</div>
                <div class="quarto-category">code</div>
                <div class="quarto-category">musicgen</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Nate Raw </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 24, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block column-page" id="quarto-document-content">





<p>This post will bring you through my motivations and process for training MusicGen Songstarter, a fine-tuned MusicGen model that produces useful samples for music producers.</p>
<p>This is not a research paper. However, much like a research paper, there is a bit of a long winded background below here to give you some context. Skip to <a href="#the-plan">the plan</a> if you want to get straight to the technical details.</p>
<section id="my-background-in-music" class="level2">
<h2 class="anchored" data-anchor-id="my-background-in-music">My Background in Music</h2>
<p>Before I got into programming, I used to spend my free time producing music. I spent countless hours in middle school downloading various software onto the family computer and infecting it with viruses (sorry Mom!). Nobody I knew at school was into that sort of thing, so I had to go online to find folks like me who were tinkering with music production. Once I found a few friends via [what I imagine were] Soundcloud DMs, we formed a Facebook group to chat, collaborate, share our music, and ask technical questions.</p>
<p>This was one of my first real experiences with an online, collaborative community. It was such a beautiful thing. Through collaborating with folks in this group, I was ‚Äúsigned‚Äù to a couple record labels and released tracks on Beatport. In hindsight, the ‚Äúlabels‚Äù were probably just some dudes in their basement taking advantage of kids like me, but it was still fun to get my music out there.</p>
<p>As time went on, I got less interested in EDM and more into instrumental hip-hop/experimental music. I started producing, mixing, and mastering for local artist friends of mine. I stopped trying to market my music and just made music for myself, sometimes sharing links with friends and family. Felt more fun this way. At some point along the way, I started ramping up learning programming and ML, and basically stopped making music altogether. Pretty lame!</p>
<p>Here‚Äôs of my favorite tracks I made (Yes, I realize how wild it is to link to my Soundcloud in a ML blogpost üòÇ)</p>
<iframe width="100%" height="300" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/429181860&amp;color=%23000000&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true&amp;visual=true">
</iframe>
<div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;">
<a href="https://soundcloud.com/nateraw" title="nate raw" target="_blank" style="color: #cccccc; text-decoration: none;">nate raw</a> ¬∑ <a href="https://soundcloud.com/nateraw/thoughts" title="thoughts" target="_blank" style="color: #cccccc; text-decoration: none;">thoughts</a>
</div>
</section>
<section id="ai-music-research-the-musicgen-weights-release" class="level2">
<h2 class="anchored" data-anchor-id="ai-music-research-the-musicgen-weights-release">AI music research + the MusicGen weights release</h2>
<p>I may have put my DJing career on the backburner, but over the years I‚Äôve tried to keep up with the intersection of AI and music. When I saw the papers for MuLan/MusicLM, I started to get really excited. MusicLM showed a LOT of potential. But of course, Google chose not to release the weights. üò≠</p>
<p>A year later, in Jan 2024, Meta dropped the code AND weights for MusicGen. This model was a bit simpler in architecture compared to MusicLM - it takes audio and tokenizes it with <code>Encodec</code>, then feeds it to a transformer. They showed how you could control the generation by conditioning on text, melody, metadata, etc. The hype was <strong>real</strong>!! üî•</p>
<p>With the excitement also came some minor frustrations‚Ä¶it was exciting because it was a huge step forward in the field of AI music generation - <strong>and</strong> the weights were open. Frustrating because the Encodec model used to train the larger variants of MusicGen was for <strong><strong>32khz mono</strong></strong> audio. A <strong><strong>44.1k/48k stereo</strong></strong> MusicGen would have earth shattering for the AI community. Instead, they teased us a bit by releasing a 48k stereo <code>Encodec</code>, but made it frustrating to use in their training codebase, so nobody could practically train a new MusicGen checkpoint with it (if I‚Äôm mistaken about this, please let me know and I‚Äôll revise!). Even if you could, you‚Äôd need a bunch of compute to make it happen.</p>
<p>After some time, Meta released ‚Äústereo‚Äù variants of the MusicGen models with a bit of a hack to interleave codebooks for left and right channels - still using the mono Encodec under the hood. I‚Äôve heard these described as being ‚Äútoo stereo‚Äù, which I tend to agree with. Gripes aside, these stereo models are still INCREDIBLE and I am so grateful for their release. üôè</p>
</section>
<section id="musicgen---will-it-finetune" class="level2">
<h2 class="anchored" data-anchor-id="musicgen---will-it-finetune">MusicGen - will it finetune?</h2>
<p>A few months after the release of MusicGen, when there were still just mono models available, I started wondering: how hard it would be to fine-tune this? Just like with any large pretrained model, you often get the best results for your use case by finetuning on your own data. I had a hunch that finetuning MusicGen on a dataset of music samples could produce some really cool results.</p>
<p>My first idea was to fine-tune on specific artists. Basically ‚Äúgenerate a song that sounds like &lt;artist&gt; made it‚Äù. So, I started tinkering with the <a href="https://github.com/facebookresearch/audiocraft">audiocraft</a> codebase, trying to figure out how the training code worked, how to format the data, etc. For me, the codebase is a bit hard to follow. Nested Hydra configs, a PyTorch trainer suite, <a href="https://github.com/facebookresearch/flashy"><code>flashy</code></a>, that lives in a different github repo, an experiment manager, <a href="https://github.com/facebookresearch/dora"><code>dora</code></a>, that also lives in a different repo. It‚Äôs a lot to take in!!</p>
<section id="initial-experiments-with-fine-tuning-on-artists" class="level4">
<h4 class="anchored" data-anchor-id="initial-experiments-with-fine-tuning-on-artists">Initial experiments with fine-tuning on artists</h4>
<p>After some exploration, I figured out how to get training running using their codebase, and prepared a dataset of samples from a few artists and started training for the text-to-music task, starting from the <a href="https://huggingface.co/facebook/musicgen-small">musicgen-small</a> checkpoint as that was the largest model I could fit on a Google Colab A100 40gb GPU. For the dataset, since I didn‚Äôt have text captions for the music, I set the captions to be the same every time: ‚Äúan electronic instrumental in the style of <artist>‚Äù.</artist></p>
<p>The results were‚Ä¶okay. I had to generate a lot of samples to get some good ones out‚Ä¶most were riddled with artifacts/noise/strange sounds/silence. I also was plagued by a sneaking suspicion that the model was overfitting and just regenerating existing tracks. Here are some clips from the first model I trained, where I used a dataset of songs by <a href="https://soundcloud.com/montebooker">Monte Booker</a>:</p>
<table style="width:100%; text-align:center;">
<tbody><tr>
<th>
Text Prompt
</th>
<th>
Output
</th>
</tr>
<tr>
<td>
jazz trumpet over a hip hop beat in the style of montebooker
</td>
<td>
<audio controls="">
<source src="../static/training_musicgen_songstarter/jazz_trumpet_over_a_hip_hop_beat_in_the_style_of_montebooker.wav" type="audio/wav">
Your browser does not support the audio element. </audio>
</td>
</tr>
<tr>
<td>
reggae chords over a hip hop beat in the style of montebooker
</td>
<td>
<audio controls="">
<source src="../static/training_musicgen_songstarter/musicgenmonte_reggae_chords_over_hip_hop_beat_by_montebooker2.wav" type="audio/wav">
Your browser does not support the audio element. </audio>
</td>
</tr>
</tbody></table>
</section>
</section>
<section id="aha-moment" class="level2">
<h2 class="anchored" data-anchor-id="aha-moment">Aha moment üí°</h2>
<p>These results felt promising to me! So, I went over to Monte Booker‚Äôs discord and shared the results, asking for feedback. Immediately, folks started taking the samples I shared and remixing the tracks I sent - chopping them up, adding better drums, etc.</p>
<p>This made something click for me‚Ä¶why not make the outputs even more usable for producers? Instead of generating full tracks like I was doing, why not generate loops like you‚Äôd buy from <a href="https://splice.com">Splice</a>? This way, I‚Äôm not making an ‚ÄúAI version of the artist‚Äù, but rather creating a tool that music producers can use creatively. If done correctly, I‚Äôd get rid of most of the ethical concerns I was having while also building a more unique project.</p>
<p>This would be like the new age of sampling! ü§Ø</p>
</section>
<section id="the-plan" class="level2">
<h2 class="anchored" data-anchor-id="the-plan">The plan</h2>
</section>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<p>All these years, I‚Äôve been subscribed to <a href="https://splice.com">Splice</a> but not producing much music. As a result, I had accumulated a lot of credits. So, my plan was to download a bunch of loops from Splice and use those to train a new model.</p>
<section id="downloading-the-data" class="level4">
<h4 class="anchored" data-anchor-id="downloading-the-data">Downloading the data</h4>
<p>Nothing too fancy here. I sat at my computer and listened to samples for a long time - listening and purchasing samples carefully. Some key notes from this process:</p>
<ul>
<li>I wanted to stick with samples that matched my taste. I went for hip hop/rap/electronic melodic loops, as well as some soul/jazz samples.
<ul>
<li>I had to be careful not to download samples that were too similar to each other. Often times sample packs had complimentary samples that were too similar to each other. I wanted to make sure the model was learning a wide variety of sounds.</li>
<li>I wanted samples to be 15-30s long (note MusicGen was trained on 30s samples).</li>
<li>I wanted to avoid drums altogether so the model would un-learn to generate drums.</li>
</ul></li>
</ul>
<p>For the songstarter-v0.1, I used ~600 samples. For songstarter-v0.2, I used around 1700-1800 samples - about 7-8 hours of audio altogether.</p>
</section>
<section id="data-prep" class="level3">
<h3 class="anchored" data-anchor-id="data-prep">Data prep</h3>
<p>I prepared metadata JSON files following the audiocraft repo‚Äôs examples. I set the tags to be the ‚Äúdescription‚Äù, formatting it like:</p>
<pre><code>{tag_1}, {tag_1}, ..., {tag_n}, {key}, {bpm} bpm</code></pre>
<p>For example:</p>
<pre><code>hip hop, soul, piano, chords, jazz, neo jazz, G# minor, 140 bpm</code></pre>
<p>I included bpm and key attributes in the audiocraft JSON metadata files as well (<em>which, looking back, means they were included twice in the input to the model sometimes</em>). I also included the genre if it was available. I left mood and instruments blank.</p>
</section>
<section id="training" class="level3">
<h3 class="anchored" data-anchor-id="training">Training</h3>
<section id="audiocraft-woes-rewriting-training-w-pytorch-lightning" class="level4">
<h4 class="anchored" data-anchor-id="audiocraft-woes-rewriting-training-w-pytorch-lightning">Audiocraft Woes + rewriting training w/ PyTorch Lightning</h4>
<p>Once I felt I had a good dataset to start training medium/large models, I would spin up a VM on <a href="https://lambdalabs.com">Lambda</a>, and try to start training with the original training code from audiocraft. Unfortunately, in addition to the codebase being hard to navigate (which I attribute to the nested Hydra configs), I ran into a lot of issues with training itself.</p>
<p>Specifically, there were bugs when using FSDP that caused deadlocks. When you‚Äôre spending your own personal $$$, you want the training to be as efficient as possible, so not being able to use FSDP reliably was an issue.</p>
<p>So, I rewrote the training loop with PyTorch Lightning, as its a nice tool to use when you‚Äôre trying to focus on the model rather than the training loop. This worked. The one major headache my implementation causes is that the checkpoints are saved different than the original <code>audiocraft</code> checkpoints‚Ä¶but at least it works!</p>
<blockquote class="blockquote">
<p>As a quick aside, I think some of my issues with FSDP in <code>audiocraft</code> may have been H100 specific. There are some lingering issues on their GitHub about it. My implementation also had some issues on H100 that I am not 100% sure are resolved. Had limited time to debug because every hour spent not training was ~$30. I actually ended up burning most of the credits Lambda gave me for this project just on one 12 hour session debugging FSDP issues on an 8xH100. üò≠ The final training run was done on 8xA100 40GB.</p>
</blockquote>
<p>The training code I used is available via my fork of the audiocraft repo <a href="https://github.com/nateraw/audiocraft">here</a>. Note I did not add the validation loop here - I found I was evaluating the model by generating samples and listening to them, so I didn‚Äôt bother with it. Again, I was doing most of this on my own time, so I was moving quickly.</p>
</section>
<section id="training-details" class="level4">
<h4 class="anchored" data-anchor-id="training-details">Training details</h4>
<p>I don‚Äôt have the exact details for v0.1, which was a medium melody model, so we‚Äôll just discuss <code>musicgen-songstarter-v0.2</code>.</p>
<p>v0.2 was fine-tuned on top of <a href="https://huggingface.co/facebook/musicgen-stereo-melody-large"><code>facebook/musicgen-stereo-melody-large</code></a> on a Lambda Labs 8xA100 40gb instance for 10k steps, which took about 6 hours. With FSDP, I could safely fit a batch size of 5 per device, so that‚Äôs what I used (meaning global batch size of 40). I reduced the minimum segment duration to 15s (from the base model‚Äôs 30s). The code is available <a href="https://github.com/nateraw/audiocraft">here</a>, but is undocumented as of now.</p>
<p>I tried a few different combos of batch size / segment duration to find what made sense for me. In the end, even though we trained on smaller samples, the model can still generate longer samples - at the cost (or benefit, depending who you ask) of the fact they are usually looping.</p>
</section>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>I don‚Äôt have any quantitative results to show here. I figured it would be unfair to eval against MusicCaps as an eval, since my model is for a more specific use case. Its prompts weren‚Äôt natural language, but instead lists of tags. Instead, I encourage you to hear what it can do!</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>I‚Äôm really excited about the future of AI Music for music producers. I hope to keep working in this space and provide music producers tools that they can use to elevate their creativity - NOT replace them. After all, what I‚Äôm trying to create here is something I would want to use myself.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/www\.nateraw\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>